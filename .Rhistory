R --version
> version
setwd("C:/Apps/GitHub Repositories/cm2018_ht25_seminar_4_b2")
## === Setup ===================================================================
# Clear workspace
rm(list = ls())
# Load packages (only base R is strictly needed here)
# install.packages("ggplot2")
library(ggplot2)
## === Import data =============================================================
# Read Cyfra 21-1 data
data <- read.csv("data_t2.csv")
# Check names
names(data)
# Replace 'Cyfra_Kit1' and 'Cyfra_Kit2' with the actual column names
kit1 <- data$Cyfra_Kit1
kit2 <- data$Cyfra_Kit2
# Quick summary
summary(kit1)
summary(kit2)
## === Kit 1 vs. Kit 2 ======================================================
# Scatter plot (association, not agreement)
plot(
x = kit1,
y = kit2,
xlab = "Cyfra 21-1 (Kit 1) [ng/mL]",
ylab = "Cyfra 21-1 (Kit 2) [ng/mL]",
main = "Scatter plot of Cyfra 21-1: Kit 1 vs Kit 2"
)
abline(a = 0, b = 1, col = "red", lwd = 2)  # line of identity
# Regression line (Kit2 ~ Kit1)
model <- lm(kit2 ~ kit1)
abline(model, col = "blue", lwd = 2)
## === Correlation ======================================================
# Pearson correlation coefficient
cor_pearson <- cor(kit1, kit2, method = "pearson", use = "complete.obs")
cor_pearson
## === Paired t-test (test for systematic bias) ================================
t.test(kit1, kit2, paired = TRUE)
# Differences and means of the two kits
diff_vals <- kit1 - kit2
mean_vals <- (kit1 + kit2) / 2
# Bias and limits of agreement
bias <- mean(diff_vals, na.rm = TRUE)
sd   <- sd(diff_vals,   na.rm = TRUE)
LOA_upper <- bias + 1.96 * sd
LOA_lower <- bias - 1.96 * sd
bias
LOA_lower
LOA_upper
## === Bland–Altman analysis (agreement) -----------------------------
# Differences and means of the two kits
diff_vals <- kit1 - kit2
mean_vals <- (kit1 + kit2) / 2
# Bias and limits of agreement
bias <- mean(diff_vals, na.rm = TRUE)
sd   <- sd(diff_vals,   na.rm = TRUE)
LOA_upper <- bias + 1.96 * sd
LOA_lower <- bias - 1.96 * sd
bias
LOA_lower
LOA_upper
t.test(kit1, kit2, paired = TRUE)
## === Bland–Altman analysis (agreement) -----------------------------
# Differences and means of the two kits
diff_vals <- kit1 - kit2
mean_vals <- (kit1 + kit2) / 2
# Bias and limits of agreement
bias <- mean(diff_vals, na.rm = TRUE)
sd   <- sd(diff_vals,   na.rm = TRUE)
LOA_upper <- bias + 1.96 * sd
LOA_lower <- bias - 1.96 * sd
bias
LOA_lower
LOA_upper
# Base R Bland–Altman plot
plot(
x = mean_vals,
y = diff_vals,
xlab = "Mean Cyfra 21-1 (Kit 1 & Kit 2) [ng/mL]",
ylab = "Difference Cyfra 21-1 (Kit 1 - Kit 2) [ng/mL]",
main = "Bland–Altman plot: Cyfra 21-1"
)
abline(h = bias,      col = "blue", lwd = 2)        # mean difference (bias)
abline(h = LOA_upper, col = "darkgreen", lty = 2)   # upper LOA
abline(h = LOA_lower, col = "darkgreen", lty = 2)   # lower LOA
View(data)
## === Sensitivity, Specificity, and Kappa =====================================
# 3.3 ng/mL clinical cut-off
cutoff <- 3.3
# Classification for each kit
kit1_class <- ifelse(kit1 >= cutoff, 1, 0)
kit2_class <- ifelse(kit2 >= cutoff, 1, 0)
# Confusion matrix (Kit 1 vs Kit 2)
conf_mat <- table(Kit1 = kit1_class, Kit2 = kit2_class)
conf_mat
# Sensitivity and specificity (Kit 2 = reference)
TP <- conf_mat["1", "1"]
TN <- conf_mat["0", "0"]
FP <- conf_mat["1", "0"]
FN <- conf_mat["0", "1"]
sensitivity <- TP / (TP + FN)
specificity <- TN / (TN + FP)
sensitivity
specificity
# Cohen's Kappa
# Install if needed: install.packages("irr")
library(irr)
install.packages("irr")
library(irr)
kappa2(cbind(kit1_class, kit2_class))
library(epiR)
epi.ccc(kit1, kit2)
# Interpretation:
# 1.00 = perfect agreement
# 0.90–0.99 = excellent
# 0.75–0.90 = good
# <0.75 = poor agreement
model <- lm(diff_vals ~ mean_vals)
plot(model)
qqnorm(diff_vals); qqline(diff_vals)
# If differences are strongly non-normal → consider transformation (e.g. log)
